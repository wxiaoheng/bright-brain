# 从零搭建我的"数字化外脑"：AI应用实战与复盘笔记

## 写在前面
上一篇里，我靠着"嘴遁"（Prompt）成功编出了一个Electron+Vue3的前端壳子。现在，这个壳子虽然长得挺像回事，但本质上还是个植物人——没灵魂，更没记忆。接下来主要的工作就是用代码给它注入灵魂。
针对技术栈的选型，正经AI工程师肯定首选Python，毕竟"亲生的"，库多、生态好。但作为一个"不正经"的野生技术宅，我的技术栈哲学是：不是看你有什么，而是看我会什么。
所以，在这两年的折腾里，主要关注的还是Java和TypeScript技术栈，后面的主要后端逻辑实现，我也准备在这两条路上各走一遍，不是为了对比谁强谁弱，纯粹是一个技术宅的恶趣味——我想看看，用这两种截然不同的画风去撩拨同一个大模型，会有什么不同的快感。


这里重点把 LangGraph 引入进来，虽然对于简单的对话功能来说它有点“杀鸡用牛刀”，但这正是为后面 Agent 章节埋下的重要伏笔。

# 02. 用TypeScript让外脑活起来

正式写代码之前，还是照旧先对几个名词进行瞎解释。

## 非著名术语瞎解释

### 1. Context Window (上下文窗口)
*   **专业版**：上下文窗口是指模型单次处理信息时能够参考的文本范围上限，通常以Token数量衡量，它构成了模型的"短期工作记忆"……
*   **瞎解释版**：**AI 的"脑容量"大小**。
    *   大模型不记事儿，每次问它问题，都得把之前的对话（历史记录）和新的问题，一股脑递给它。
    *   但它脑子是有容量限制的（比如 8k、128k）。如果聊天记录太多，它脑子就会爆炸，拒绝工作，就得想办法缩减内容（比如把最早的记录扔掉）。
	
### 2. Multimodal (多模态)
*   **专业版**：处理和整合多种类型媒体信息（文本、图像、音频）的能力……
*   **瞎解释版**：**给 AI 装上眼睛和耳朵**。
    *   以前的AI是瞎子和聋子，只能靠摸盲文（文字）然后回答。有了多模态能力之后它就是一个正常人了，给它一张图片/一段音视频，它都能看到/听到，能理解它的意思。
	

### 3. LangGraph 
*   **专业版**：是一个用于构建有状态、多步骤智能体（Agent）应用的开源框架。它通过图结构来编排复杂的工作流，让AI应用能够像项目管理一样，记住执行状态、支持循环和分支，并能随时暂停与恢复……
*   **瞎解释版**：**给 AI 画"流程图"的工头**。
    *   以前就是直接调AI接口，是"直肠子"模式————问->答。
    *   LangGraph 允许我们设计复杂的脑回路（比如先思考->再搜索->搜不到再换个词搜->最后回答）。它把这套逻辑抽象成了"节点"和"连线"，是后面我们要做的 Agent（智能体）的基石。

---

##第一步：注入灵魂-连接大模型

连接大模型，最开始我用的是直接的http请求，后来用的各大模型官方SDK（如OpenAI），最后发现了 **LangChain**，它帮我磨平了不同模型（OpenAI, Anthropic, 甚至是本地的 Ollama）之间的接口差异。

但光连上还不够，最重要的是**体验**。

还记得我在第一篇里提到的“打字机效果”吗？在后端实现里，这其实就是把 HTTP 响应变成了一个长连接管道。

我用 `express` 搭建了服务器，核心逻辑大概是这样的：

```typescript
// 伪代码：流式响应的实现逻辑
app.post('/chat', async (req, res) => {
  // 告诉前端：别挂电话，我要开始念经了
  res.setHeader('Content-Type', 'text/event-stream'); 
  
  const stream = await model.stream("请给我讲个鬼故事");
  
  for await (const chunk of stream) {
    // 就像挤牙膏，一点点挤给前端
    res.write(`data: ${JSON.stringify({ content: chunk })}\n\n`);
  }
  
  res.end(); // 讲完了，挂电话
});
```

当我第一次看到终端里那些字符像黑客帝国一样蹦出来的时候，那种成就感，啧啧，比修好一个 NullPointer 爽多了。

### 💾 第二步：治疗健忘症（SQLite + 记忆管理）

连通了模型，紧接着我就发现了一个大问题：**这货是属金鱼的，记忆只有7秒。**
上一句我刚说“我叫张三”，下一句问它“我叫啥”，它就一脸懵逼。

这是因为 LLM 本身是无状态的（Stateless）。为了让它有记忆，我得自己做一个“海马体”。

我选择了 **SQLite**。为什么？
*   **MySQL/PostgreSQL**：太重了，我就是个本地应用，不想装个 Docker 跑数据库。
*   **JSON 文件**：太 Low 了，聊多了文件太大，读写性能扛不住。
*   **SQLite**：刚刚好，一个文件就是数据库，Node.js 的 `better-sqlite3` 库跑起来飞快。

我的设计逻辑很简单：
1.  **建表**：一张 `sessions` 表存会话列表，一张 `messages` 表存每一句聊天记录。
2.  **存**：用户发一句，存进去；AI 回一句，存进去。
3.  **取**：每次发新消息前，先把在这个 Session 下的最近 20 条记录（这就是**上下文窗口**的策略）查出来，打包发给 AI。

这里有个坑：**千万不能把所有历史记录都发过去！**
一开始我没做限制，聊了几天后发现 API 账单爆炸，而且报错说 Token 超出上限。后来我乖乖加了个**“滑动窗口”**算法，只保留最近的 N 轮对话，或者当 Token 总数超过阈值时，自动丢弃最早的记录。

### 🕸️ 第三步：引入 LangGraph —— 杀鸡用牛刀？

既然能对话了，能存库了，为啥还要引入 **LangGraph** 这么复杂的概念？

坦白说，如果是为了实现简单的“你问我答”，LangGraph 确实是过度设计。但我这毕竟是奔着“数字化外脑”去的，后面我要让它帮我查文档、写代码、甚至自动提交 Git。

如果用普通的 `if-else` 来写这些复杂逻辑，代码最后会变成一坨难以维护的“意大利面条”。

LangGraph 的美妙之处在于，它让我用**状态机（State Machine）**的思维来写代码。

我定义了一个简单的图（Graph）：
1.  **State（状态）**：包含 `messages` 数组。
2.  **Node（节点）**：
    *   `modelNode`：负责调用大模型生成回复。
    *   `toolNode`：负责调用外部工具（后面会用到）。
3.  **Edge（边）**：逻辑判断。比如“如果模型决定调用工具，就走到 toolNode，否则直接结束”。

在 Node.js 里实现大概长这样：

```typescript
// 定义一个简单的图
const workflow = new StateGraph(MessagesAnnotation)
  .addNode("agent", callModel)  // 节点：AI思考
  .addNode("tools", toolNode)   // 节点：工具执行
  .addEdge("__start__", "agent") // 起点 -> AI
  .addConditionalEdges("agent", shouldContinue); // AI -> 决定是结束还是用工具

const app = workflow.compile({ checkpointer: mySqliteSaver }); // 绑定数据库
```

看到最后那个 `checkpointer` 了吗？LangGraph 甚至帮我把“保存对话状态到数据库”这一步都自动化了。我只需要写好业务逻辑，它自动帮我快照保存当前的对话状态。

这不仅是代码的整洁，更是**思维的升级**。我现在看着这个图，脑子里已经开始构思后面怎么让它根据我的 PDF 文档自动跳转节点了。

### 🖼️ 顺手搞定：多模态（给它安个眼睛）

既然用了 GPT-4o 或者 Claude 3.5 这种多模态模型，不发图片岂不是浪费？

在 Node.js 里处理这个很简单，其实就是把前端传过来的图片转成 Base64 字符串，或者直接扔一个 URL 给模型。

只不过我在存数据库的时候做了点变通：
*   **图片太大，不存 SQLite**。
*   我在本地搞了个 `uploads` 文件夹存图片文件。
*   数据库里只存文件路径 `file://...`。
*   发给 AI 时，再读取文件转成 Base64。

这样，我的外脑不仅能陪聊，还能帮我看 UI 图写代码了（虽然它现在的审美还有待提高）。

### 小结

用 Node.js 写 AI 后端，给我最大的感受就是**“丝滑”**。
不用切换思维模式，不用处理 Python 环境依赖的那些糟心事儿（懂的都懂 `pip install` 报错的痛）。

虽然 LangGraph 上手曲线有点陡峭，文档看懂一半靠猜，但一旦跑通了，看着那个有向无环图在代码里运转，你会觉得：**嗯，这不仅仅是个聊天机器人，这像是一个正在孕育的智慧生命体。**

不过，作为一个喜欢折腾的人，只用 Node.js 显然不能满足我的胃口。
听说 Java 生态最近出了个 **Spring AI**，号称要统一企业级 AI 开发？

作为一个写了多年 Java 的老兵，这我能忍？
下一篇，我们要搞点“企业级”的狠活。我将用 **Java + Spring AI** 重新复刻一遍这个后端逻辑，顺便聊聊，在 AI 应用开发上，Java 到底是“大象起舞”还是“廉颇老矣”。